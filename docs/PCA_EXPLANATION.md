# PCA Implementation for Gait Analysis - Technical Overview

## Executive Summary for Project Lead

This document explains the PCA (Principal Component Analysis) implementation added to GaitVision as an **educational comparison tool** alongside the existing neural network autoencoder.

**Key Points:**
- PCA provides a simpler, interpretable alternative to the autoencoder
- Both methods reduce 9 gait features to a 2D space for classification
- The implementation allows side-by-side comparison of linear vs non-linear approaches
- PCA typically captures 70-85% of variance (acceptable but not perfect)
- Useful for understanding which features matter most (interpretability)

---

## 1. What is PCA?

### Simple Explanation
PCA finds the "best angles" to look at high-dimensional data. Instead of looking at 9 different measurements individually, it finds 2 directions that capture most of the variation.

**Analogy:**
Imagine filming a walking person:
- You could place 9 cameras at different angles (9 features)
- But 2 well-positioned cameras (2 principal components) capture most of the useful information
- PCA finds those optimal 2 camera angles automatically

### Technical Explanation
PCA is a **linear dimensionality reduction technique** that:
1. Centers the data (subtract mean)
2. Computes the covariance matrix
3. Finds eigenvectors (principal components)
4. Projects data onto top components

The first principal component (PC1) points in the direction of maximum variance.
The second (PC2) is orthogonal to PC1 and captures the next most variance.

### Mathematical Formula
```
For input x (9D feature vector):
1. Normalize: x_scaled = (x - mean) / std
2. Project: z = x_scaled Ã— W    where W is (9Ã—2) PCA matrix
3. Result: z is a 2D point [zâ‚, zâ‚‚]
```

---

## 2. Why Use PCA for Gait Analysis?

### Educational Value
- **Interpretability**: We can see which features (knee angles, torso, stride) contribute most to each component
- **Baseline**: Establishes if a simple linear method is sufficient before using complex neural networks
- **Comparison**: Demonstrates the value of non-linear methods (autoencoder) when PCA isn't enough

### Practical Advantages
- âœ… **Fast**: Matrix multiplication (~0.1ms) vs autoencoder inference (~10ms)
- âœ… **Simple**: No neural network training required
- âœ… **Deterministic**: Same input always gives same output
- âœ… **Interpretable**: Can analyze component loadings
- âœ… **Small**: 72 bytes vs 50KB model file

### When PCA Works Well
- Gait features are **linearly separable** (clean vs impaired form distinct clusters)
- Variance-based dimensionality reduction captures the relevant information
- We're okay with capturing ~70-80% of variance

### When PCA Falls Short
- Non-linear relationships between features (autoencoder captures these)
- Complex interaction effects (e.g., knee angle Ã— stride length)
- Classes overlap in linear projections

---

## 3. Your Implementation: The Pipeline

### Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GaitVision Pipeline                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Video â†’ Pose Detection â†’ Angle Extraction â†’ Feature Engineering
   â†“           â†“                 â†“                   â†“
30 fps     33 landmarks      7 angles         Local min/max
video      per frame         per frame        statistics

                            â†“
                   [9 Feature Vector]
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                   â”‚
    [Z-score Normalize]              [Z-score Normalize]
          â”‚                                   â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Autoencoderâ”‚                     â”‚    PCA     â”‚
    â”‚  (Neural)  â”‚                     â”‚  (Linear)  â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                   â”‚
      [2D Latent]                         [2D PC]
          â”‚                                   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         [Distance to Centroids]
                     â†“
           [Gait Score 0-100]
```

### The 9 Features (Input)
```
1. Left Knee Min Angle        - Minimum extension during gait cycle
2. Left Knee Max Angle        - Maximum flexion during gait cycle  
3. Right Knee Min Angle       - Minimum extension during gait cycle
4. Right Knee Max Angle       - Maximum flexion during gait cycle
5. Torso Min Angle            - Most backward lean
6. Torso Max Angle            - Most forward lean
7. Stride Length Average      - Average step distance
8. Left Knee Range            - Max - Min (mobility indicator)
9. Right Knee Range           - Max - Min (mobility indicator)
```

**Why these 9?**
- Clinically relevant for gait assessment
- Captured reliably by pose detection
- Used by the existing autoencoder (fair comparison)
- Represent key biomechanical parameters

### PCA Training Process

**Input Data:**
- Clean gait: Nâ‚ participants Ã— 9 features
- Impaired gait: Nâ‚‚ participants Ã— 9 features
- Total: (Nâ‚ + Nâ‚‚) Ã— 9 matrix

**Training Steps:**
```python
# Step 1: Standardization (z-score)
X_scaled = (X - mean) / std

# Step 2: Fit PCA
pca = PCA(n_components=2)
pca.fit(X_scaled)

# Result: 9Ã—2 transformation matrix
# PC1: [wâ‚â‚, wâ‚â‚‚, wâ‚â‚ƒ, ..., wâ‚â‚‰]
# PC2: [wâ‚‚â‚, wâ‚‚â‚‚, wâ‚‚â‚ƒ, ..., wâ‚‚â‚‰]

# Step 3: Transform all data
X_pca = pca.transform(X_scaled)  # Shape: (Nâ‚+Nâ‚‚) Ã— 2

# Step 4: Compute centroids
clean_centroid = mean(X_pca[clean_participants])
impaired_centroid = mean(X_pca[impaired_participants])
```

**Output Files for Android:**
```
pca_components.bin          72 bytes    9Ã—2 transformation matrix
clean_centroid_pca.bin       8 bytes    2D point [x, y]
impaired_centroid_pca.bin    8 bytes    2D point [x, y]
```

### Android Inference Process

```kotlin
// 1. Extract 9 features (same as autoencoder)
val inputData = floatArrayOf(
    leftKneeMinAngles.average(),
    leftKneeMaxAngles.average(),
    // ... 7 more features
)

// 2. Standardize (z-score normalize)
val scaledInput = FloatArray(9) { i ->
    (inputData[i] - scalerMean[i]) / scalerScale[i]
}

// 3. PCA transformation: 9D â†’ 2D
val pcaComponents = loadFloatBinFile("pca_components.bin")  // 9Ã—2 matrix
val latentSpace = FloatArray(2)

for (i in 0..1) {  // For each PC
    latentSpace[i] = 0f
    for (j in 0..8) {  // For each input feature
        latentSpace[i] += scaledInput[j] * pcaComponents[j * 2 + i]
    }
}
// Result: latentSpace = [PC1_value, PC2_value]

// 4. Calculate distances to centroids
val distClean = euclideanDistance(latentSpace, cleanCentroid)
val distImpaired = euclideanDistance(latentSpace, impairedCentroid)

// 5. Compute gait score
val score = 100 Ã— [1 - (distClean / (distClean + distImpaired))]
```

---

## 4. PCA vs Autoencoder: Technical Comparison

### Similarity: Both Create 2D Representations

| Aspect | PCA | Autoencoder |
|--------|-----|-------------|
| **Input** | 9 features | 9 features |
| **Output** | 2D point | 2D point |
| **Goal** | Maximize variance | Minimize reconstruction error |
| **Classification** | Distance to centroids | Distance to centroids |
| **Scoring** | Same formula | Same formula |

### Key Differences

| Aspect | PCA | Autoencoder |
|--------|-----|-------------|
| **Type** | Linear transformation | Non-linear neural network |
| **Training** | Eigenvalue decomposition | Gradient descent |
| **Complexity** | Simple (9Ã—2 matrix mult) | Complex (neural layers) |
| **Inference Speed** | ~0.1ms | ~5-10ms |
| **Model Size** | 72 bytes | ~50 KB |
| **Interpretability** | High (can analyze loadings) | Low (black box) |
| **Captures** | Linear correlations | Non-linear patterns |
| **Variance Captured** | Typically 70-85% | Reconstruction-based (not directly comparable) |

### When Each is Better

**PCA is better if:**
- Features are linearly correlated
- You need interpretability
- Speed/size matters
- You want deterministic results

**Autoencoder is better if:**
- Complex non-linear patterns exist
- You have lots of training data
- Accuracy > interpretability
- Willing to sacrifice explainability

---

## 5. How to Interpret Results

### The 2D Visualization

When you run `train_pca.py`, you get a scatter plot:

```
PC2 (30% var) â†‘
              â”‚
         ğŸŸ¢   â”‚   ğŸ”´
       ğŸŸ¢ ğŸŸ¢  â”‚  ğŸ”´ ğŸ”´
      ğŸŸ¢ ğŸŸ¢ â­ | â­ ğŸ”´ ğŸ”´    â† Impaired centroid
       ğŸŸ¢ ğŸŸ¢  â”‚  ğŸ”´ ğŸ”´
         ğŸŸ¢   â”‚   ğŸ”´
              â”‚
      â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ PC1 (55% var)
       Clean  â”‚
     centroid â­

ğŸŸ¢ = Clean gait participants (score ~90-100)
ğŸ”´ = Impaired gait participants (score ~0-50)
â­ = Centroids (average positions)
```

**Good separation:** Green and red are distinct â†’ PCA works well  
**Overlap:** Colors mixed â†’ PCA struggles, autoencoder likely better

### Component Loadings (Feature Importance)

PCA tells you which features matter most:

```
PC1 Loadings (55% variance):
â”œâ”€ Left Knee Range:     +0.45  (high positive)
â”œâ”€ Right Knee Range:    +0.43  (high positive)
â”œâ”€ Left Knee Max:       +0.38
â”œâ”€ Right Knee Max:      +0.35
â”œâ”€ Stride Length:       +0.28
â”œâ”€ Torso angles:        Â±0.15  (low)

Interpretation: PC1 mainly captures knee mobility
```

This tells you: **Knee range of motion is the most important discriminator** between clean and impaired gait.

### Explained Variance Ratio

```
PC1: 55%  â† Captures 55% of total data variance
PC2: 30%  â† Captures additional 30%
Total: 85% â† We retain 85% of information
Lost: 15%  â† Discarded (hopefully not critical)
```

**Rule of thumb:**
- â‰¥80%: Good, PCA is suitable
- 70-80%: Acceptable, but check results carefully
- <70%: Poor, autoencoder probably better

### Centroid Distance

```
Distance = ||clean_centroid - impaired_centroid||

â‰¥1.0: Good separation, clear distinction
0.5-1.0: Moderate separation, some overlap expected
<0.5: Poor separation, hard to classify
```

---

## 6. Strengths and Limitations

### Strengths of This Implementation

âœ… **Educational Value**
- Shows difference between linear and non-linear methods
- Demonstrates feature importance
- Teaches dimensionality reduction concepts

âœ… **Practical Benefits**
- 100Ã— faster than autoencoder
- 700Ã— smaller model file
- Works offline (no neural network runtime)
- Deterministic and reproducible

âœ… **Clinical Insight**
- Reveals which biomechanical features matter most
- Component loadings are interpretable by physical therapists
- Can validate autoencoder findings

### Limitations to Acknowledge

âŒ **Assumes Linearity**
- May miss complex feature interactions
- Example: Impact of knee angle depends on stride length (non-linear)

âŒ **Variance â‰  Relevance**
- Maximizes variance, not classification accuracy
- Might capture irrelevant variations (e.g., participant height effects)

âŒ **No Feature Learning**
- Uses handcrafted features (the 9 inputs)
- Autoencoder can learn better representations

âŒ **Less Flexible**
- Can't adapt to new data patterns
- Fixed linear transformation

### Comparison Results (Hypothetical)

If PCA score â‰ˆ Autoencoder score:
â†’ "Linear method sufficient, simpler is better"

If PCA score â‰  Autoencoder score:
â†’ "Non-linear patterns exist, autoencoder captures more information"

---

## 7. Questions Your Project Lead Might Ask

### Q1: "Why add PCA if we already have an autoencoder?"

**Answer:**
"This is an **educational feature** to demonstrate the difference between linear and non-linear dimensionality reduction. By showing both scores side-by-side, users can:

1. Understand if a simple linear method is sufficient for their data
2. See which biomechanical features are most important (PCA loadings)
3. Validate that the autoencoder is necessary (if scores differ significantly)
4. Learn about machine learning approaches in a practical context

It's not meant to replace the autoencoderâ€”it's a teaching tool."

### Q2: "How much training data do you need?"

**Answer:**
"Minimum 10 clean + 10 impaired participants, but 25+ each is recommended. PCA needs:
- Enough samples to estimate covariance matrix (at least 2-3Ã— the number of features)
- Diverse participants to capture population variance
- Balanced classes for accurate centroid estimation

With 9 features, we ideally want 30-50 samples per class."

### Q3: "What if PCA performs poorly?"

**Answer:**
"That's actually valuable information! Poor PCA performance indicates:
1. Gait impairment has non-linear patterns (validates autoencoder use)
2. Feature interactions matter (can't be captured by linear combination)
3. The problem is complex enough to justify deep learning

We can quantify 'poor' as:
- Explained variance <70%
- Centroid distance <0.5
- Low correlation between PCA and autoencoder scores"

### Q4: "How do you validate the PCA model?"

**Answer:**
"Three validation steps:

1. **Explained Variance**: Check that PC1+PC2 capture â‰¥70% of variance
2. **Visualization**: Verify classes separate in 2D scatter plot
3. **Cross-validation**: Test on held-out participants

We also compare against the autoencoder on the same test set to measure correlation."

### Q5: "Can you explain the math without using jargon?"

**Answer:**
"Sure! Think of it like cooking:

**The Recipe (PCA):**
1. Take 9 measurements from each person's gait
2. Find 2 'summary measurements' that capture most of the variation
3. Convert everyone's 9 measurements into these 2 summaries
4. Plot clean vs impaired people using the 2 summaries
5. Find the average position of each group (centroids)
6. For a new person, convert their 9 measurements to 2, see which group they're closer to

**The Math:**
- 'Finding 2 summaries' = computing principal components
- 'Convert' = matrix multiplication
- 'Closer to' = Euclidean distance"

### Q6: "What's the computational complexity?"

**Answer:**

**Training (offline, once):**
- O(n Ã— dÂ²) where n=samples, d=features
- For 50 participants Ã— 9 features: ~0.01 seconds
- Negligible compared to video processing

**Inference (on-device, real-time):**
- O(d Ã— k) where d=features, k=components
- 9 Ã— 2 = 18 multiplications + 18 additions
- ~0.1ms on modern phones (vs ~10ms for autoencoder)"

### Q7: "How do you handle the scaler mismatch issue?"

**Answer:**
"The app already has `scaler_mean.bin` and `scaler_scale.bin` for the autoencoder. We **reuse the same scaler** for PCA to ensure:

1. Fair comparison (both methods see identically normalized data)
2. Consistency (one source of truth for normalization)
3. Simplicity (no duplicate scaler files)

During PCA training, we verify our Python scaler matches the app's scaler parameters."

---

## 8. Talking Points for Presentation

### 30-Second Pitch
"I added a PCA-based gait analysis mode alongside the existing autoencoder. Users can now see both a simple linear analysis (PCA) and complex non-linear analysis (neural network) side-by-side. This demonstrates when simple methods are sufficient and when deep learning adds valueâ€”an important lesson for understanding ML applications in healthcare."

### Key Talking Points

1. **Educational Value**: "Helps users understand dimensionality reduction and model complexity trade-offs"

2. **Interpretability**: "PCA shows which gait features (knee angles, stride, torso) matter mostâ€”clinically useful"

3. **Lightweight**: "PCA is 700Ã— smaller and 100Ã— faster, demonstrating efficiency gains of simpler models"

4. **Validation**: "If PCA and autoencoder agree, we know linear relationships dominate. If they disagree, we've proven the need for deep learning."

5. **Practical Implementation**: "Used scikit-learn for training, exported to binary files, integrated seamlessly with existing Android code"

### Demonstration Flow

1. Show the dual-score UI
2. Explain both methods process the same 9 features
3. Show a visualization where they agree (linear case)
4. Show a visualization where they diverge (non-linear case)
5. Explain the exported comparison CSV for research

---

## 9. Technical Implementation Details

### File Formats

**pca_components.bin** (72 bytes)
```
Layout: Row-major 9Ã—2 float32 matrix
[PC1_feature0, PC2_feature0,    // Row 0 (knee min L)
 PC1_feature1, PC2_feature1,    // Row 1 (knee max L)
 ...
 PC1_feature8, PC2_feature8]    // Row 8 (knee range R)

Little-endian IEEE 754 floats
Used for: 9D â†’ 2D transformation
```

**Centroids** (8 bytes each)
```
Layout: [x, y] as float32
clean_centroid_pca.bin: [0.25, -0.10]
impaired_centroid_pca.bin: [0.45, 0.15]

Used for: Distance calculations
```

### Matrix Multiplication Implementation

```kotlin
// Optimized for mobile
val latentSpace = FloatArray(2)
for (i in 0..1) {  // 2 components
    var sum = 0f
    for (j in 0..8) {  // 9 features
        sum += scaledInput[j] * pcaComponents[j * 2 + i]
    }
    latentSpace[i] = sum
}
```

**Complexity:** O(18) operations (constant time)

---

## 10. Conclusion

### Summary
- PCA provides a **fast, interpretable, linear baseline** for gait analysis
- Integrated seamlessly with existing pipeline (shares preprocessing and scoring)
- Educational value: demonstrates ML model complexity trade-offs
- Practical value: identifies important biomechanical features
- Implemented efficiently: <100 lines of new Android code

### Future Work (If Asked)
- Compare PCA vs autoencoder accuracy on larger dataset
- Try 3-component PCA for higher explained variance
- Implement Kernel PCA for non-linear variant of PCA
- A/B test: do clinicians prefer interpretable PCA or accurate autoencoder?

### The Bottom Line
"This implementation demonstrates that **understanding trade-offs** between simplicity and complexity is crucial in ML applications. PCA gives us that understanding while providing a functional, lightweight alternative when the autoencoder is overkill."

---

**Prepared by:** [Your Name]  
**Project:** GaitVision - Dual Analysis Mode  
**Branch:** feature/pca-analysis-mode  
**Date:** October 2025

